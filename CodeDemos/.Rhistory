string_same
lev.DF = which(all.values[,"cook.d"] > 4/(n-p))
new.state = data.frame(pop = state.x77[,1], income = state.x77[,2], ill = state.x77[,3], life.exp =  state.x77[,4], murder = state.x77[,5], hs.grad = state.x77[,6], frost.days = state.x77[,7], land.area = state.x77[,8])
summary(new.state)
names(new.state) = c("X1","X2","X3","Y","X4","X5","X6","X7" )
full.model = lm(Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7,data = new.state)
library(leaps)
all.models = regsubsets(Y ~ ., data = new.state, nbest=1, nvmax=7)
summary_stuff = summary(all.models)
names_of_data = c("Y",colnames(summary_stuff$which)[-1])
n = nrow(new.state) #Will have to change the name
K = nrow(summary_stuff$which)
nicer = lapply(1:K,function(i){
model = paste(names_of_data[summary_stuff$which[i,]],collapse = ",")
p = sum(summary_stuff$which[i,])
BIC = summary_stuff$bic[i]
AIC = summary_stuff$bic[i] - (log(n)* p) + 2*p
CP = summary_stuff$cp[i]
results = data.frame(model,p,CP,AIC, BIC)
return(results)
})
nicer = Reduce(rbind,nicer)
nicer
full.model = lm(Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7, data = new.state)
empty.model = lm(Y ~ 1, data = new.state)
n = nrow(new.state)
library(MASS)
forward.model.AIC = stepAIC(empty.model, scope = list(lower = empty.model, upper= full.model), k = 2,direction = "forward")
forward.model.BIC = stepAIC(empty.model,  scope = list(lower = empty.model, upper= full.model), k = log(n),direction = "forward")
forward.model.AIC = stepAIC(empty.model, scope = list(lower = empty.model, upper= full.model), k = 2,direction = "forward",trace = FALSE)
forward.model.BIC = stepAIC(empty.model,  scope = list(lower = empty.model, upper= full.model), k = log(n),trace=FALSE,direction = "forward")
forward.model.AIC$coefficients
backward.model.AIC = stepAIC(full.model, scope = list(lower = empty.model, upper= full.model), k = 2,direction = "backward",trace = FALSE)
backward.model.BIC = stepAIC(full.model,  scope = list(lower = empty.model, upper= full.model), k = log(n),trace=FALSE,direction = "backward")
FB.model.AIC = stepAIC(empty.model, scope = list(lower = empty.model, upper= full.model), k = 2,direction = "both",trace = FALSE)
FB.model.BIC = stepAIC(empty.model,  scope = list(lower = empty.model, upper= full.model), k = log(n),trace=FALSE,direction = "both")
BF.model.AIC = stepAIC(full.model, scope = list(lower = empty.model, upper= full.model), k = 2,direction = "both",trace = FALSE)
BF.model.BIC = stepAIC(full.model,  scope = list(lower = empty.model, upper= full.model), k = log(n),trace=FALSE,direction = "both")
forward.model.AIC$coefficients
backward.model.AIC$coefficients
FB.model.AIC$coefficients
BF.model.AIC$coefficients
forward.model.BIC$coefficients
backward.model.BIC$coefficients
FB.model.BIC$coefficients
BF.model.BIC$coefficients
best.model = lm(Y~X1+X4+X5+X6, data = new.state)
ei.s = best.model$residuals/sqrt(sum(best.model$residuals^2)/(nrow(new.state) - length(best.model$coefficients)))
ri = rstandard(best.model)
ti = rstudent(best.model)
alpha = 0.1 ; n = nrow(new.state); p = length(best.model$coefficients)
cutoff = qt(1-alpha/(2), n - p )
cutoff.deleted = qt(1-alpha/(2), n -p -1 )
outliers = which(abs(ti) > cutoff.deleted)
new.state[outliers,]
all.values = influence.measures(best.model)$infmat
head(all.values)
#colnames(all.values)
lev.hat = which(all.values[,"hat"] > 2*p/n)
new.state[lev.hat,]
lev.DF = which(all.values[,"dffit"] >1)
new.state[lev.DF,]
lev.DF = which(all.values[,"cook.d"] > 4/(n-p))
new.state[lev.DF,]
lev.DF = which(all.values[,"dffit"] > 2*sqrt((p+1)/(n-p-1)))
new.state[lev.DF,]
lev.hat = which(all.values[,"hat"] > 3*p/n)
new.state[lev.hat,]
lev.hat = which(all.values[,"hat"] > 2*p/n)
new.state[lev.hat,]
# uncorrelated predictor variables
X1 = c(4,4,4,4,6,6,6,6)
X2 = c(2,2,3,3,2,2,3,3)
Y = c(42,39,48,51,49,53,61,60)
plot(X1,X2)
cor(X1,X2)
lm(Y~X1+X2)
lm(Y~X1)
lm(Y~X2)
anova(lm(Y~X2+X1))
anova(lm(Y~X1))
anova(lm(Y~X1+X2))
anova(lm(Y~X2))
summary(lm(Y~X1+X2))
summary(lm(Y~X1))
?anova
anova(lm(Y~X1+X2))
anova(lm(Y~X2+X1))
anova(lm(Y~X1+X2))
anova(lm(Y~X2))
summary(lm(Y~X1+X2))
summary(lm(Y~X1))
# perfectly correlated
X1 = c(2,8,6,10)
X2 = c(6,9,8,10)
par(mfrow=c(1,1))
plot(X1,X2)
Y = c(23,83,63,103)
cor(X1,X2)
X = cbind(rep(1,4),X1,X2)
XtX = t(X) %*% X
XtX
solve(XtX)
eigen(XtX)
eigen(XtX)$values
#matrix not invertible! rank deficient (not full rank)
-87 + X1 + 18*X2
-7 + 9*X1 + 2*X2
#Variance Inflation
X1=runif(100, 25, 50)
X2=rnorm(100, 10, 3)
eps=rnorm(100, 0 ,4)
Y=7+3*X1+5*X2+eps
mod1=lm(Y~X1+X2)
summary(mod1)
#create a nearly perfectly collinear variable
X3=2*X1+3*X2+rnorm(100,0,.01)
cor(X1,X3)
cor(X2,X3)
cor(2*X1+3*X2,X3)
mod2=lm(Y~X1+X2+X3)
summary(mod2)
summary(mod1)
summary(mod2)
# uncorrelated predictor variables
X1 = c(4,4,4,4,6,6,6,6)
X2 = c(2,2,3,3,2,2,3,3)
Y = c(42,39,48,51,49,53,61,60)
plot(X1,X2)
Y = c(42,39,48,51,49,53,61,60)
cor(X1,X2)
lm(Y~X1+X2)
lm(Y~X1)
lm(Y~X2)
anova(lm(Y~X2+X1))
anova(lm(Y~X1))
anova(lm(Y~X1+X2))
anova(lm(Y~X2))
summary(lm(Y~X1+X2))
summary(lm(Y~X1))
anova(lm(Y~X1+X2))
# perfectly correlated
X1 = c(2,8,6,10)
X2 = c(6,9,8,10)
cor(X1,X2)
plot(X1,X2)
Y = c(23,83,63,103)
X = cbind(rep(1,4),X1,X2)
X
XtX = t(X) %*% X
XtX
#zero eigen value
eigen(XtX)
#singular matrix!
4.813655e+02
#singular matrix!
solve(XtX)
#matrix not invertible! rank deficient (not full rank)
-87 + X1 + 18*X2
-7 + 9*X1 + 2*X2
#Variance Inflation
X1=runif(100, 25, 50)
X2=rnorm(100, 10, 3)
eps=rnorm(100, 0 ,4)
Y=7+3*X1+5*X2+eps
mod1=lm(Y~X1+X2)
summary(mod1)
cor(X1, X2)
Y=7+3*X1+5*X2+eps
mod1=lm(Y~X1+X2)
summary(mod1)
#create a nearly perfectly collinear variable
X3=2*X1+3*X2+rnorm(100,0,.01)
cor(X1,X3)
cor(X2,X3)
cor(2*X1+3*X2,X3)
mod2=lm(Y~X1+X2+X3)
summary(mod2)
summary(mod1)
summary(mod2)
summary(mod1)
summary(mod2)
summary(mod1)
summary(mod2)
#Variance Inflation
X1=runif(100, 25, 50)
X2=rnorm(100, 10, 3)
eps=rnorm(100, 0 ,4)
cor(X1, X2)
Y=7+3*X1+5*X2+eps
mod1=lm(Y~X1+X2)
summary(mod1)
#create a nearly perfectly collinear variable
X3=2*X1+3*X2+rnorm(100,0,.01)
cor(X1,X3)
cor(X2,X3)
cor(2*X1+3*X2,X3)
mod2=lm(Y~X1+X2+X3)
summary(mod2)
summary(mod1)
summary(mod2)
vif_model = lm(X3 ~ X1 + X2)
summary(vif_model)
sum = summary(vif_model)
r2j = sum$r.squared
vif_j = 1/(1-r2j)
vif_j
(vif_j>10)
summary(mod1)
summary(mod2)
summary(mod1)
89.858^2 / 0.06063^2
vif_j
vif1_model = lm(X1 ~ X2 + X3)
sum = summary(vif1_model)
#2 Calc R2 for this model (Model j)
r21 = sum$r.squared
vif_1 = 1/(1-r21)
#3. Check vs. cutoff (4 or 10)
(vif_1>10)
vif_1
89.858^2 / 0.06063^2
x = 1:10
mean(x)
var(x)
sd(x)
median(x)
quantile(x, probs = 0.25) #Q1
quantile(x, probs = 0.75) #Q3
iqr(x)
IQR(x)
quantile(x, probs = 0.75) - quantile(x, probs = 0.25) #IQR = Q3 - Q1
iris[,1:4]
?apply
apply(iris[,1:4], 1, mean)
apply(iris[,1:4], 2, mean)
x = 1:5
y = 5:1
cor(x,y)
state.x77
?state.x77
library(ggplot2)
colnames(state.x77)
ggplot(state.x77, aes(x = Income,
y = Illiteracy)) +
geom_point()
df = as.data.frame(state.x77)
ggplot(df, aes(x = Income,
y = Illiteracy)) +
geom_point()
cor(df$Income, df$Illiteracy)
colnames(state.x77)
ggplot(df, aes(x = Income,
y = Population)) +
geom_point()
cor(df$Income, df$Population)
####Benchmarking
library(microbenchmark)
set.seed(100)
x = runif(min = 0, max = 1, n = 100)
x
micro = microbenchmark(sqrt(x), x^0.5, times = 1000)
micro
1614.744/661.863
set.seed(100)
x = runif(min = 0, max = 1, n = 100)
micro = microbenchmark(sqrt(x), x^0.5, x^0.25, x^2, sin(x), times = 1000)
micro
mod2 = lm(y~x + I(x^2), data = df)
library(ggplot2)
library(ggpubr)
set.seed(372)
x = runif(100, min = 0, max = 10)
y = 1 + x*(x - 4)*(x - 9) + rnorm(100, mean = 0, sd = 10)
df = data.frame(x = x, y = y)
ggplot(df, aes(x = x , y = y)) +
geom_point()
mod1 = lm(y ~ x, data = df)
df$resid_linear = residuals(mod1)
df$fitted_linear = fitted(mod1)
ggplot(df) +
geom_point(aes(x = x, y = y)) +
geom_line(aes(x = x, y = fitted_linear), color = "red") +
ggtitle("Fitted values from linear reg (red)")
ggplot(df, aes(x = x, y = resid_linear)) +
geom_point()
mod2 = lm(y~x + I(x^2), data = df)
mod3 = lm(y~x + I(x^2) + I(x^3), data = df)
mod4 = lm(y~x + I(x^2) + I(x^3) + I(x^4), data = df)
mod5 = lm(y~x + I(x^2) + I(x^3) + I(x^4) + I(x^5), data = df)
summary(mod2)
summary(mod3)
summary(mod4)
summary(mod5)
check = function(df, model){
data = df
data$resid = residuals(model)
data$fitted = fitted(model)
gg1 = ggplot(data = data) +
geom_point(mapping = aes(x = x, y = y)) +
geom_line(mapping =  aes(x = x, y = fitted), color = "red")
gg2 = ggplot(data,
aes(x = x, y = resid)) +
geom_point()
gg1
gg2
output = list(fitted = gg1, resid = gg2)
return(output)
}
check(df, mod2)
check(df, mod3)
check(df, mod4)
check(df, mod5)
#generate formula
p = 75
formula_vec = rep(NA, p)
for(i in 1:p){
formula_vec[i] = paste0("I(x^", i,")")
}
formula_preds = paste0(formula_vec, collapse = "+")
formula = paste0("y~", formula_preds)
modp = lm(formula, data = df)
check(df, modp)
anova(mod2)
anova(mod3)
anova(mod4)
anova(mod5)
library(ggplot2)
library(ggpubr)
set.seed(372)
x = runif(100, min = 0, max = 10)
y = 1 + x*(x - 4)*(x - 9) + rnorm(100, mean = 0, sd = 10)
df = data.frame(x = x, y = y)
ggplot(df, aes(x = x , y = y)) +
geom_point()
mod1 = lm(y ~ x, data = df)
df$resid_linear = residuals(mod1)
df$fitted_linear = fitted(mod1)
ggplot(df) +
geom_point(aes(x = x, y = y)) +
geom_line(aes(x = x, y = fitted_linear), color = "red") +
ggtitle("Fitted values from linear reg (red)")
ggplot(df, aes(x = x, y = resid_linear)) +
geom_point()
mod2 = lm(y~x + I(x^2), data = df)
mod3 = lm(y~x + I(x^2) + I(x^3), data = df)
mod4 = lm(y~x + I(x^2) + I(x^3) + I(x^4), data = df)
mod5 = lm(y~x + I(x^2) + I(x^3) + I(x^4) + I(x^5), data = df)
summary(mod2)
summary(mod3)
summary(mod4)
summary(mod5)
check = function(df, model){
data = df
data$resid = residuals(model)
data$fitted = fitted(model)
gg1 = ggplot(data = data) +
geom_point(mapping = aes(x = x, y = y)) +
geom_line(mapping =  aes(x = x, y = fitted), color = "red")
gg2 = ggplot(data,
aes(x = x, y = resid)) +
geom_point()
gg1
gg2
output = list(fitted = gg1, resid = gg2)
return(output)
}
check(df, mod2)
check(df, mod3)
check(df, mod4)
check(df, mod5)
#generate formula
p = 75
formula_vec = rep(NA, p)
for(i in 1:p){
formula_vec[i] = paste0("I(x^", i,")")
}
formula_preds = paste0(formula_vec, collapse = "+")
formula = paste0("y~", formula_preds)
modp = lm(formula, data = df)
check(df, modp)
anova(mod2)
anova(mod3)
anova(mod4)
anova(mod5)
library(ggplot2)
library(ggpubr)
set.seed(372)
x = runif(100, min = 0, max = 10)
y = 1 + x*(x - 4)*(x - 9) + rnorm(100, mean = 0, sd = 15)
df = data.frame(x = x, y = y)
ggplot(df, aes(x = x , y = y)) +
geom_point()
mod1 = lm(y ~ x, data = df)
df$resid_linear = residuals(mod1)
df$fitted_linear = fitted(mod1)
ggplot(df) +
geom_point(aes(x = x, y = y)) +
geom_line(aes(x = x, y = fitted_linear), color = "red") +
ggtitle("Fitted values from linear reg (red)")
ggplot(df, aes(x = x, y = resid_linear)) +
geom_point()
mod2 = lm(y~x + I(x^2), data = df)
mod3 = lm(y~x + I(x^2) + I(x^3), data = df)
mod4 = lm(y~x + I(x^2) + I(x^3) + I(x^4), data = df)
mod5 = lm(y~x + I(x^2) + I(x^3) + I(x^4) + I(x^5), data = df)
summary(mod2)
summary(mod3)
summary(mod4)
summary(mod5)
check = function(df, model){
data = df
data$resid = residuals(model)
data$fitted = fitted(model)
gg1 = ggplot(data = data) +
geom_point(mapping = aes(x = x, y = y)) +
geom_line(mapping =  aes(x = x, y = fitted), color = "red")
gg2 = ggplot(data,
aes(x = x, y = resid)) +
geom_point()
gg1
gg2
output = list(fitted = gg1, resid = gg2)
return(output)
}
check(df, mod2)
check(df, mod3)
check(df, mod4)
check(df, mod5)
#generate formula
p = 75
formula_vec = rep(NA, p)
for(i in 1:p){
formula_vec[i] = paste0("I(x^", i,")")
}
formula_preds = paste0(formula_vec, collapse = "+")
formula = paste0("y~", formula_preds)
modp = lm(formula, data = df)
check(df, modp)
anova(mod2)
anova(mod3)
anova(mod4)
anova(mod5)
library(ggplot2)
library(ggpubr)
set.seed(372)
x = runif(100, min = 0, max = 10)
y = 1 + x*(x - 4)*(x - 9) + rnorm(100, mean = 0, sd = 20)
df = data.frame(x = x, y = y)
ggplot(df, aes(x = x , y = y)) +
geom_point()
mod1 = lm(y ~ x, data = df)
df$resid_linear = residuals(mod1)
df$fitted_linear = fitted(mod1)
ggplot(df) +
geom_point(aes(x = x, y = y)) +
geom_line(aes(x = x, y = fitted_linear), color = "red") +
ggtitle("Fitted values from linear reg (red)")
ggplot(df, aes(x = x, y = resid_linear)) +
geom_point()
mod2 = lm(y~x + I(x^2), data = df)
mod3 = lm(y~x + I(x^2) + I(x^3), data = df)
mod4 = lm(y~x + I(x^2) + I(x^3) + I(x^4), data = df)
mod5 = lm(y~x + I(x^2) + I(x^3) + I(x^4) + I(x^5), data = df)
summary(mod2)
summary(mod3)
summary(mod4)
summary(mod5)
check = function(df, model){
data = df
data$resid = residuals(model)
data$fitted = fitted(model)
gg1 = ggplot(data = data) +
geom_point(mapping = aes(x = x, y = y)) +
geom_line(mapping =  aes(x = x, y = fitted), color = "red")
gg2 = ggplot(data,
aes(x = x, y = resid)) +
geom_point()
gg1
gg2
output = list(fitted = gg1, resid = gg2)
return(output)
}
check(df, mod2)
check(df, mod3)
check(df, mod4)
check(df, mod5)
#generate formula
p = 75
formula_vec = rep(NA, p)
for(i in 1:p){
formula_vec[i] = paste0("I(x^", i,")")
}
formula_preds = paste0(formula_vec, collapse = "+")
formula = paste0("y~", formula_preds)
modp = lm(formula, data = df)
check(df, modp)
anova(mod2)
anova(mod3)
anova(mod4)
anova(mod5)
set.seed(372)
x1 = runif(100, min = 0, max = 10)
x2 = runif(100, min = 0, max = 10)
y = 5 + 10*x1^2 - 5*x1*x2 + 3*x2^2 + rnorm(100, 0, 1)
df2 = data.frame(x1 = x1 ,x2 = x2, y = y )
quadintmod = lm(y~x1 + x2 + I(x1^2) + I(x2^2) + x1:x2, #this last one is the interaction
data = df2)
summary(quadintmod)
intmod = lm(y~.^2, #only interactions, not quad terms
data = df2)
summary(intmod)
